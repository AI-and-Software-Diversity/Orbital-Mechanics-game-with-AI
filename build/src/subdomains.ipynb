{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-locking",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lightweight-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.7.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helpers as h\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9f0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(filepath_data, filepath_setup):\n",
    "    \"\"\"\n",
    "    Takes the data csv and the setup csv and combines them into \n",
    "    1 larger csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_1 = pd.read_csv(filepath_data, sep=',')\n",
    "    df_2 = pd.read_csv(filepath_setup, sep=',')\n",
    "    \n",
    "    \n",
    "    #reference for concat: https://www.youtube.com/watch?v=iYWKfUOtGaw\n",
    "    df_rl = pd.concat([df_1, df_2], axis=1)\n",
    "    df_rl.columns = df_rl.columns.str.replace(' ', '')\n",
    "\n",
    "    return df_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73efea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_df(df, cols, i, operator, pivot):\n",
    "    if operator == \">\":\n",
    "        return (df[cols[i]] > pivot)\n",
    "    else:\n",
    "        return (df[cols[i]] <= pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64bdf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_random_filters_given_columns(dataframe):\n",
    "    \"\"\"\n",
    "    Using the column titles, and the min/max of the column, \n",
    "    this function returns a random boolean condition or filter\n",
    "    \"\"\"\n",
    "\n",
    "    #     list of the columns\n",
    "    #     lists of the min/max value of each column\n",
    "    \n",
    "    excluded_cols = ['wassuccesful',\n",
    "                     'reward',\n",
    "                     'actualsteps',\n",
    "                     'targetsteps',\n",
    "                     'runscompleted',\n",
    "                     'length',\n",
    "                     'height']\n",
    "    \n",
    "    cols = [col for col in dataframe.columns if col not in excluded_cols]\n",
    "    i = random.randint(0,len(cols)-1)\n",
    "    \n",
    "    maxs = [dataframe[col].max() for col in cols]\n",
    "    mins = [dataframe[col].min() for col in cols]\n",
    "\n",
    "#     print(i)\n",
    "#     print(maxs)\n",
    "#     print(mins)\n",
    "    \n",
    "    filt_info = []\n",
    "    pivot = random.randint(mins[i], \n",
    "                           maxs[i])\n",
    "    b = random.randint(0,1)\n",
    "    \n",
    "    if b == 0:\n",
    "#         filt = (dataframe[cols[i]] > pivot)\n",
    "        filt = filtered_df(dataframe, cols, i, \">\", pivot)\n",
    "        \n",
    "        filt_info.append((dataframe, cols, i, \">\", pivot))\n",
    "#         print(f\"{cols[i]}>{pivot}\")\n",
    "    else:\n",
    "#         filt = (dataframe[cols[i]] <= pivot)\n",
    "        filt = filtered_df(dataframe, cols, i, \"<=\", pivot)\n",
    "        filt_info.append((dataframe, cols, i, \"<=\", pivot))\n",
    "#         print(f\"{cols[i]}<={pivot}\")\n",
    "    \n",
    "    \n",
    "    return filt, filt_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9f375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_reward_given_filters(dataframe, fltr):\n",
    "    \"\"\"\n",
    "    Given a table of data (like a csv or a dataframe) it finds the average \n",
    "    reward after filtering the table\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter the dataframe\n",
    "    # reference fro loc: https://www.youtube.com/watch?v=Lw2rlcxScZY\n",
    "    df_avg = dataframe.loc[fltr, 'reward']\n",
    "#     print(pd.DataFrame(df_avg))\n",
    "    \n",
    "    \n",
    "    # get the average of those that meet our conditions\n",
    "    avg_reward = np.mean(df_avg)\n",
    "    \n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46cf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl11\n",
    "path = \"/home/javonne/Uni/Orbital-Mechanics-game-with-AI/build/agents/2_star_2_planet/rl1\"\n",
    "filepath_data = f\"/{path}/data_rlearn.csv\"\n",
    "filepath_setup = f\"/{path}/setup_rlearn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7457876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rl = create_dataframe(filepath_data, filepath_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a494eee7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filt, _ = get_random_filters_given_columns(df_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f2d242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-168.99622641509433"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_reward_given_filters(df_rl, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16905dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_domain_search(df_agent_1, agent_1, df_agent_2, agent_2):\n",
    "    \n",
    "    fitness_subdomain_winner = []\n",
    "    \n",
    "    # 1. You have two CSVs containing data that corresponds to two agents.\n",
    "    # via params\n",
    "    \n",
    "    # you ensure each data tihng has the same columns\n",
    "    if list(df_agent_1.columns) != list(df_agent_2.columns):\n",
    "        raise Exception(\"These dataframes have different columns and cannot be compared. Perhaps the corresponding agents were trained with different inputs?\")\n",
    "    \n",
    "        \n",
    "    # 4. You create one or many random filters given the columns from the parameter, and the min/max of those columns.\n",
    "    filt, filt_conditions = get_random_filters_given_columns(df_agent_1)\n",
    "\n",
    "    #  check the performance of each agent in chosen filter\n",
    "    agent_1_performance = average_reward_given_filters(df_agent_1, filt)\n",
    "    agent_2_performance = average_reward_given_filters(df_agent_2, filt)\n",
    "\n",
    "    difference = np.abs(agent_1_performance - agent_2_performance)\n",
    "\n",
    "    # 6. You record all of the filters and which CSV has a higher reward (in a tuple like: Tuple[filter_conditions, better] ).\n",
    "    if agent_1_performance >= agent_2_performance:\n",
    "        fitness_subdomain_winner.append((difference, filt_conditions, agent_1))\n",
    "    else:\n",
    "        fitness_subdomain_winner.append((difference, filt_conditions, agent_2))\n",
    "\n",
    "#     print(fitness_subdomain_winner)\n",
    "#     print(fitness_subdomain_winner[0][0])\n",
    "#     print(np.array(fitness_subdomain_winner).shape)\n",
    "    \n",
    "    # put biggest differences at the top of the list\n",
    "#     fitness_subdomain_winner = fitness_subdomain_winner.sort()\n",
    "#     fitness_subdomain_winner = fitness_subdomain_winner.reverse()\n",
    "    \n",
    "    return fitness_subdomain_winner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1246ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sub_domain_search() missing 1 required positional argument: 'agent_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40145/710688770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscovered_subdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_domain_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_rl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sub_domain_search() missing 1 required positional argument: 'agent_2'"
     ]
    }
   ],
   "source": [
    "discovered_subdomain = sub_domain_search(df_rl, df_rl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40aad5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discovered_subdomain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40145/2818912359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'discovered_subdomain' is not defined"
     ]
    }
   ],
   "source": [
    "discovered_subdomain[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c74ec1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d88a77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discovered_subdomain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40145/4262054328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscovered_subdomain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'discovered_subdomain' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_df(discovered_subdomain[0][1][0][0], discovered_subdomain[0][1][0][1], discovered_subdomain[0][1][0][2], discovered_subdomain[0][1][0][3], discovered_subdomain[0][1][0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2500c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b35a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429327a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcc6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77484e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psuedocode\n",
    "# def sub_domain_search(csv_1, csv_2, [columns_to_search], number_of_checks):\n",
    "#     filter_and_better = []\n",
    "#     columns_1 = csv_1.columns\n",
    "#     columns_2 = csv_2.columns\n",
    "#     if columns_1 != columns_2:\n",
    "#         raise Exception\n",
    "#     for i in range(number_of_checks):\n",
    "#         filter_1 = get_random_filters_given_columns(csv_1)\n",
    "#         filter_2 = get_random_filters_given_columns(csv_2)\n",
    "#         avg_1 = average_reward_given_filters(csv_1, filter_1)\n",
    "#         avg_2 = average_reward_given_filters(csv_2, filter_2)\n",
    "#         if avg_1 >= avg_2:\n",
    "#             result = (filter_1, 0)\n",
    "#         else:\n",
    "#             result = (filter_2, 1)\n",
    "#         filter_and_better.append(result)\n",
    "#     return filter_and_better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10343e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = [(8,3,3),(6,5,5),(7,1,62)]\n",
    "np.array(stuff).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ff9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9612626",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe495e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stuff[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71308dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c66fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae2b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c1304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa92cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a33f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4894a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b788c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d99a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18487b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390e083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f27d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facef33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f7050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e513dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373fc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a375379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ff597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525f331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e9b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2b90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b18281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94578333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d6ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e23be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0dde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_sub_domain_search(df_agent_1, df_agent_2, num_checks):\n",
    "    \n",
    "    fitness_subdomain_winner = []\n",
    "    \n",
    "    # 1. You have two CSVs containing data that corresponds to two agents.\n",
    "    # via params\n",
    "    \n",
    "    # you ensure each data tihng has the same columns\n",
    "    if list(df_agent_1.columns) != list(df_agent_2.columns):\n",
    "        raise Exception(\"These dataframes have different columns and cannot be compared. Perhaps the corresponding agents were trained with different inputs?\")\n",
    "    \n",
    "    # 7. You do this check N times.\n",
    "    for i in range(num_checks):\n",
    "        \n",
    "        # 4. You create one or many random filters given the columns from the parameter, and the min/max of those columns.\n",
    "        filt, filt_conditions = get_random_filters_given_columns(df_agent_1)\n",
    "        \n",
    "        #  check the performance of each agent in chosen filter\n",
    "        agent_1_performance = average_reward_given_filters(df_agent_1, filt)\n",
    "        agent_2_performance = average_reward_given_filters(df_agent_2, filt)\n",
    "        \n",
    "        difference = np.abs(agent_1_performance - agent_2_performance)\n",
    "        \n",
    "        # 6. You record all of the filters and which CSV has a higher reward (in a tuple like: Tuple[filter_conditions, better] ).\n",
    "        if agent_1_performance >= agent_2_performance:\n",
    "            fitness_subdomain_winner.append((difference, filt_conditions, \"agent_1\"))\n",
    "        else:\n",
    "            fitness_subdomain_winner.append((difference, filt_conditions, \"agent_2\"))\n",
    "    \n",
    "#     print(fitness_subdomain_winner)\n",
    "#     print(fitness_subdomain_winner[0][0])\n",
    "#     print(np.array(fitness_subdomain_winner).shape)\n",
    "    \n",
    "    # put biggest differences at the top of the list\n",
    "#     fitness_subdomain_winner = fitness_subdomain_winner.sort()\n",
    "#     fitness_subdomain_winner = fitness_subdomain_winner.reverse()\n",
    "    \n",
    "    return fitness_subdomain_winner\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
